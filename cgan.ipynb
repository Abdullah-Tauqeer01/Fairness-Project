{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/local/data0/software/miniconda3/envs/clam/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from func.helper import generate_embeddings,EmbeddingDataset,Generator,Discriminator\n",
    "import numpy as np\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import tensorflow as tf  # Import TensorFlow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ast import literal_eval\n",
    "import torch.nn.functional as F\n",
    "import os "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/data0/home/atauqeer/Negin/func/helper.py:366: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['race_index'] = filtered_data['race'].map(race_to_index)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if CUDA is available and set PyTorch to use CUDA or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = EmbeddingDataset('balanced_df.csv.gz')\n",
    "\n",
    "\n",
    "embedding_dim = 1376\n",
    "race_dim = 2\n",
    "hidden_dim = 512\n",
    "batch_size = 512\n",
    "lr = 0.00002\n",
    "epochs = 300\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "generator = Generator(embedding_dim, race_dim, hidden_dim).to(device)\n",
    "discriminator = Discriminator(embedding_dim, race_dim, hidden_dim).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "# Define the directory path\n",
    "save_dir = 'savedweights'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Define the standard deviation for the noise\n",
    "noise_std = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_embeddings, races) in enumerate(data_loader):\n",
    "        if len(races) != batch_size:\n",
    "            break\n",
    "        real_embeddings = real_embeddings.to(device)\n",
    "        races = F.one_hot(races, num_classes=2).to(device)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Add noise to the real embeddings\n",
    "        noisy_real_embeddings = real_embeddings + torch.randn_like(real_embeddings) * noise_std\n",
    "        outputs = discriminator(noisy_real_embeddings, races)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        noise = torch.randn(batch_size, embedding_dim).to(device)\n",
    "        fake_embeddings = generator(noise, races)\n",
    "\n",
    "        # Add noise to the fake embeddings\n",
    "        noisy_fake_embeddings = fake_embeddings + torch.randn_like(fake_embeddings) * noise_std\n",
    "        outputs = discriminator(noisy_fake_embeddings.detach(), races)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        outputs = discriminator(fake_embeddings, races)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(data_loader)} \\\n",
    "                  Loss D: {d_loss_real.item()+d_loss_fake.item()}, loss G: {g_loss.item()}\")\n",
    "\n",
    "    torch.save(generator.state_dict(), f'{save_dir}/generator_epoch_{epoch}.pt')\n",
    "    torch.save(discriminator.state_dict(), f'{save_dir}/discriminator_epoch_{epoch}.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST Code : (generating 10 examples for race index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings:\n",
      "tensor([[ 0.9673, -0.8214, -0.7557,  ..., -0.9629,  0.9245,  0.8999],\n",
      "        [ 0.9771, -0.7713, -0.8164,  ..., -0.9757,  0.9681,  0.9172],\n",
      "        [ 0.9357, -0.7177, -0.6751,  ..., -0.9326,  0.8680,  0.8434],\n",
      "        ...,\n",
      "        [ 0.9333, -0.6618, -0.7196,  ..., -0.9284,  0.9016,  0.8024],\n",
      "        [ 0.8802, -0.6808, -0.5730,  ..., -0.9226,  0.7798,  0.8203],\n",
      "        [ 0.8291, -0.5403, -0.5325,  ..., -0.8475,  0.8027,  0.6759]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from func.helper import Generator, generate_embeddings\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check if CUDA is available and set PyTorch to use CUDA or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the dimensions and other parameters\n",
    "embedding_dim = 1376\n",
    "race_dim = 6\n",
    "hidden_dim = 256\n",
    "num_examples = 10\n",
    "race_index = 0\n",
    "\n",
    "# Initialize the generator model and move it to the appropriate device\n",
    "generator = Generator(embedding_dim, race_dim, hidden_dim).to(device)\n",
    "# Load the saved weights and move to the same device\n",
    "generator.load_state_dict(torch.load('savedweights/generator_epoch_1.pt', map_location=device))\n",
    "# Set the model to evaluation mode\n",
    "generator.eval()\n",
    "\n",
    "# Generate embeddings\n",
    "generated_embeddings = generate_embeddings(generator, num_examples, race_index, embedding_dim)\n",
    "\n",
    "print(\"Generated Embeddings:\")\n",
    "print(generated_embeddings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving all examples in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from func.helper import Generator, generate_embeddings\n",
    "\n",
    "# Check if CUDA is available and set PyTorch to use CUDA or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the dimensions and other parameters\n",
    "embedding_dim = 1376\n",
    "race_dim = 6\n",
    "hidden_dim = 256\n",
    "num_examples = 1000  # Increase the number of examples\n",
    "race_index = 0\n",
    "\n",
    "# Initialize the generator model and move it to the appropriate device\n",
    "generator = Generator(embedding_dim, race_dim, hidden_dim).to(device)\n",
    "# Load the saved weights and move to the same device\n",
    "generator.load_state_dict(torch.load('/savedweights/generator_epoch_9.pt', map_location=device))\n",
    "# Set the model to evaluation mode\n",
    "generator.eval()\n",
    "\n",
    "# Generate embeddings\n",
    "generated_embeddings = []\n",
    "batch_size = 100  # Adjust the batch size based on available memory\n",
    "num_batches = num_examples // batch_size\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_batches):\n",
    "        embeddings_batch = generate_embeddings(generator, batch_size, race_index, embedding_dim)\n",
    "        generated_embeddings.append(embeddings_batch)\n",
    "\n",
    "# Concatenate batches into a single tensor\n",
    "generated_embeddings = torch.cat(generated_embeddings, dim=0)\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "save_dir = \"test_examples\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save each embedding as a separate file\n",
    "for i, embedding in enumerate(generated_embeddings):\n",
    "    file_path = os.path.join(save_dir, f\"embedding_{i}.pt\")\n",
    "    torch.save(embedding, file_path)\n",
    "\n",
    "print(\"Embeddings saved successfully in the test_examples directory.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making npz file for all the generated examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Directory containing embeddings\n",
    "embeddings_dir = \"test_examples\"\n",
    "\n",
    "# Initialize a list to store embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Iterate over files in the directory\n",
    "for filename in os.listdir(embeddings_dir):\n",
    "    if filename.endswith(\".pt\"):\n",
    "        # Load the embedding tensor\n",
    "        file_path = os.path.join(embeddings_dir, filename)\n",
    "        embedding = torch.load(file_path)\n",
    "        embeddings.append(embedding.numpy())\n",
    "\n",
    "# Stack embeddings into a single numpy array\n",
    "combined_embeddings = np.stack(embeddings)\n",
    "\n",
    "# Save combined embeddings to a NPZ file\n",
    "np.savez(\"combined_embeddings.npz\", embeddings=combined_embeddings)\n",
    "\n",
    "print(\"Combined embeddings saved successfully as combined_embeddings.npz.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
